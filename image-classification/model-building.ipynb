{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cc0966",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c2b8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0bab53",
   "metadata": {},
   "source": [
    "### Menentukan path citra uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee03ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = \"data/test/\"\n",
    "image1 = test_images_path + \"Image_165.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0b9cf",
   "metadata": {},
   "source": [
    "### Membuat pipeline sekaligus pelatihan agar nantinya dapat digunakan untuk inferensi citra baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cc8aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_path, target_size=(128, 128)):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    return image\n",
    "\n",
    "def remove_background(image_path):\n",
    "    with open(image_path, 'rb') as input_file:\n",
    "        input_data = input_file.read()\n",
    "        output_data = remove(input_data)  \n",
    "    image = Image.open(io.BytesIO(output_data)).convert(\"RGBA\")\n",
    "    return image\n",
    "\n",
    "def extract_color_moments(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    if len(image_array.shape) == 2:  \n",
    "        image_array = np.stack((image_array,) * 3, axis=-1)\n",
    "    elif image_array.shape[2] == 4: \n",
    "        image_array = image_array[:, :, :3]  \n",
    "    \n",
    "    mean = np.mean(image_array, axis=(0, 1))\n",
    "    std_dev = np.std(image_array, axis=(0, 1))\n",
    "    skewness = skew(image_array.reshape(-1, image_array.shape[2]), axis=0)\n",
    "    \n",
    "    return np.concatenate([mean, std_dev, skewness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a802774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_size=(128, 128), remove_bg=False, temp_dir=None):\n",
    "        self.target_size = target_size\n",
    "        self.remove_bg = remove_bg\n",
    "        self.temp_dir = temp_dir if temp_dir else 'temp_processed_images'\n",
    "        \n",
    "        if self.remove_bg and not os.path.exists(self.temp_dir):\n",
    "            os.makedirs(self.temp_dir)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        \n",
    "        for i, image_path in enumerate(X):\n",
    "            if self.remove_bg:\n",
    "                img = remove_background(image_path)\n",
    "                temp_path = os.path.join(self.temp_dir, f\"temp_{i}.png\")\n",
    "                img.save(temp_path)\n",
    "                img = resize_image(temp_path, self.target_size)\n",
    "                \n",
    "                feature_vector = extract_color_moments(temp_path)\n",
    "            else:\n",
    "                img = resize_image(image_path, self.target_size)\n",
    "                feature_vector = extract_color_moments(image_path)\n",
    "                \n",
    "            features.append(feature_vector)\n",
    "            \n",
    "        return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d9760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_butterfly_dataset(base_path=\"data/masked-train-set/\"):\n",
    "    classes = [\"Adonis\", \"Clouded Sulphur\", \"Scarce Swallow\"]\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    label_map = {i: cls for i, cls in enumerate(classes)}\n",
    "    \n",
    "    for i, cls in enumerate(classes):\n",
    "        class_path = os.path.join(base_path, cls)\n",
    "        class_images = glob.glob(os.path.join(class_path, \"*.jpg\")) + \\\n",
    "                        glob.glob(os.path.join(class_path, \"*.jpeg\")) + \\\n",
    "                        glob.glob(os.path.join(class_path, \"*.png\"))\n",
    "        \n",
    "        image_paths.extend(class_images)\n",
    "        labels.extend([i] * len(class_images))\n",
    "    \n",
    "    return image_paths, labels, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b27d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterfly_classification_pipeline(base_path=\"data/masked-train-set/\", \n",
    "                                    target_size=(128, 128), \n",
    "                                    remove_bg=False,\n",
    "                                    test_size=0.3,\n",
    "                                    random_state=42):\n",
    "    image_paths, labels, label_map = prepare_butterfly_dataset(base_path)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        image_paths, labels, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('feature_extraction', ImageFeatureExtractor(target_size=target_size, remove_bg=remove_bg)),\n",
    "        ('classifier', KNeighborsClassifier(n_neighbors=3))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    os.makedirs('model/labelmap', exist_ok=True)\n",
    "\n",
    "    joblib.dump(pipeline, 'model/butterfly_classifier.joblib')\n",
    "    with open(f\"model/labelmap/butterfly_classifier_labels.txt\", 'w') as f:\n",
    "        for label_id, label_name in label_map.items():\n",
    "            f.write(f\"{label_id}:{label_name}\\n\")\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=[label_map[i] for i in range(len(label_map))])\n",
    "    \n",
    "    return pipeline, report, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c741dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butterfly Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Adonis       1.00      0.96      0.98        28\n",
      "Clouded Sulphur       1.00      0.96      0.98        25\n",
      " Scarce Swallow       0.94      1.00      0.97        31\n",
      "\n",
      "       accuracy                           0.98        84\n",
      "      macro avg       0.98      0.97      0.98        84\n",
      "   weighted avg       0.98      0.98      0.98        84\n",
      "\n",
      "Prediction for new image: Adonis\n",
      "Temp folder removed successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_path = \"data/masked-train-set/\"\n",
    "    \n",
    "    trained_pipeline, classification_report, label_map = butterfly_classification_pipeline(\n",
    "        base_path=image_path,\n",
    "        target_size=(128, 128),\n",
    "        remove_bg=True\n",
    "    )\n",
    "    \n",
    "    print(\"Butterfly Classification Report:\")\n",
    "    print(classification_report)\n",
    "    \n",
    "    if os.path.exists(image1):\n",
    "        prediction = trained_pipeline.predict([image1])[0]\n",
    "        print(f\"Prediction for new image: {label_map[prediction]}\")\n",
    "\n",
    "    if os.path.exists(\"temp_processed_images\"):\n",
    "        shutil.rmtree(\"temp_processed_images\")\n",
    "        print(\"Temp folder removed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f74d30",
   "metadata": {},
   "source": [
    "### Kesimpulan\n",
    "Pipeline ini menggabungkan beberapa langkah preprocessing dan model klasifikasi ke dalam satu objek, sehingga memudahkan penggunaan untuk inferensi citra baru. Contoh inferensi dapat dilihat pada file [`inference.py`](https://github.com/nabilsaragih/compvis-course/blob/main/image-classification/inference.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9e93c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borneo-herb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
